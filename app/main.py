import cv2
import numpy as np
import pickle
from tensorflow.python.util.numpy_compat import np_array
from torchgen.api.cpp import return_names
from ultralytics import YOLO
from sklearn.neighbors import NearestNeighbors
from collections import defaultdict, deque
import time
import  os

videoPath = 'Z:\\WORKSPACE\\bai_do_xe\\carPark.mp4'
modelPath = 'Z:\\WORKSPACE\\bai_do_xe\models\\yolo11_finetune.pt'
gatePos = (50,360)

viTri = 'Z:\\WORKSPACE\\bai_do_xe\\xac_dinh_vi_tri\\viTri'

confidence = 0.5
iuo = 0.3
clasID = [0]

width = 107
height = 48

VT = []
VT_history = {}

model = None

def khoiTao():
    global VT, model, VT_history
    try:
        model = YOLO(modelPath)
        print('Ä‘Ã£ load yolo 11 finetune')
    except:
        print('lá»—i khi táº£i model')
        return  False
    if load_VT():
        print('khÃ´ng thá»ƒ táº¡i cÃ¡v vá»‹ trÃ­ Ä‘Ã¡nh dáº¥u')
        return False
    return  True

def load_VT():
    """Táº£i cÃ¡c vá»‹ trÃ­ Ä‘á»— xe tá»« file cÃ³ sáºµn"""
    global VT, VT_history
    try:
        with open(viTri, 'rb') as f:
            VT = pickle.load(f)
        print(f'Ä‘Ã£ táº£i {len(VT)} vá»‹ trÃ­ Ä‘á»— xe')

        #khá»Ÿi táº¡o lá»‹ch sá»­ cho má»—i chá»— Ä‘á»—
        for i in range(len(VT)):
            VT_history[i] = deque([False] * 5, maxlen=5)
        return True

    except:
        print('khÃ´ng tÃ¬m tháº¥y file vá»‹ trÃ­')

def kiemTraVT():
    global VT, VT_history

    if not VT:
        print('danh sÃ¡ch vá»‹ trÃ­ trá»‘ng')
        return False
    #kiá»ƒm tra tá»«ng vá»‹ trÃ­
    for i, vt in enumerate(VT):
        if not isinstance(vt, (tuple, list)) or len(vt) != 2:
            print(f'vi tri {i} pháº£i lÃ  2 pháº§n tá»­ ')
            return False
        if not all(isinstance(toaDo, (int,float)) for toaDo in vt):
            print(f'vá»‹ trÃ­ {i} sai kiá»ƒu dá»¯ liá»‡u')
            return False
    print(f'ÄÃ£ kiá»ƒm tra {len(VT)} chá»— Ä‘á»—')
    return True

def phatHienXe(frame):
    """phÃ¡t hiá»‡n xe sá»­ dá»¥ng yolo"""
    global model
    ketQua = model(frame, cof = confidence, iou = iuo, classes = clasID)

    cars = []

    for kq in ketQua:
        boxes = kq.boxes
        for box in boxes:
            x1,y1,x2,y2 = map(int, box.xyxy[0])
            conf = box.conf[0].item()
            id = int(box.cls[0])

            cars.append({
                'bbox': (x1, y1, x2, y2),
                'conf': conf,
                'id': id,
                'center': ((x1+x2)//2, (y1+y2)//2)
            })
    return cars

def tinhToanVungGiao(box1, box2):
    b1x1, b1y1, b1x2, b1y2 = box1
    b2x1, b2y1, b2x2, b2y2 = box2

    x1 = max(b1x1, b2x1)
    y1 = max(b1y1, b2y1)
    x2 = min(b1x2, b2x2)
    y2 = min(b1y2, b2y2)

    w_giao = max(0, x2 - x1)
    h_giao = max(0, y2 - y1)
    dienTichGiao = w_giao * h_giao

    b1_area = (b1x2-b1x1)*(b1y2-b1y1)
    b2_area = (b2x2-b2x1)*(b2y2-b2y1)

    dienTichHop = b1_area + b2_area - dienTichGiao

    if dienTichGiao > dienTichHop:
        return 0
    else:
        iou =  dienTichGiao/dienTichHop
        return iou

def kiemTraChoCoBiChiem(vt, cars):
    vt_x, vt_y = vt
    vt_rect = (vt_x, vt_y, vt_x + height, vt_y + width)

    for car in cars:
        car_box = car['bbox']

        iou = tinhToanVungGiao(vt_rect, car_box)

        if iou > 0.2:
            return True, car['conf']

    return False, 0.0

def update_spot_history(index, is_occupied):
    global VT_history
    VT_history[index].append(is_occupied)
    tiLe = sum(VT_history[index] / len(VT_history[index]))

    if tiLe > 0.6:
        return True
    else :
        return False

def timChodau(cho_dau):
    if not cho_dau:
        return None

    for cho in cho_dau:
        center = np.array([cho[0] +width/2, cho[1] +height/2])
        gate_array = np_array([gatePos])

        knn = NearestNeighbors(n_neighbors=3)
        knn.fit(center)
        distances, indices = knn.kneighbors(gate_array)

        nearest_spots= []
        for i, j in enumerate(indices[0]):
            spot = cho_dau[i]
            distance = distances[0][j]
            nearest_spots.append(spot,distance)

    return nearest_spots
def draw_packing_infor(frame, empty_spots, occupied_spots, car_count, nearest_spot= None):
    total_spots = len(VT)
    empty_count = len(empty_spots)

    cv2.putText(frame, f'cho trong {empty_count}/{total_spots}', (10,30), cv2.FONT_HERSHEY_PLAIN, 2, (255,255,255),2)
    cv2.putText(frame, f'xe phat hien {car_count}', (10,30), cv2.FONT_HERSHEY_PLAIN, 2, (255,255,255),2)

    if nearest_spot:
        spot_pos, distance = nearest_spot
        cv2.putText(frame, f'cho trong gan nha cach: {distance}', (10,100), cv2.FONT_HERSHEY_PLAIN, 2, (255,255,255),2)
    else:
        cv2.putText(frame, 'bai da day', (10,100), cv2.FONT_HERSHEY_PLAIN, 2, (255,255,255),2)

    cv2.circle(frame, gatePos, 10, (255,255,255), 2)
    cv2.putText(frame, 'cua ra vao', (gatePos[0] + 15, gatePos[1]), cv2.FONT_HERSHEY_PLAIN, 2, (255,255,255),2)
    return frame

def draw_packing_spot(frame, empty_spots, occupied_spots, cars):
    for i, spot_pos in enumerate(VT):
        if spot_pos in occupied_spots:
            color = (0,0,255)
            sttus = 'co xe'
        else:
            color = (0,255,0)
            sttus = 'trong'
        cv2.rectangle(frame, spot_pos, (spot_pos[0] + width, spot_pos[1]+height ), (255,255,255), 2)
        cv2.putText(frame,f'i+1', (spot_pos[0]+5, spot_pos[1] +15), cv2.FONT_HERSHEY_PLAIN, 2, (255,255,255),2)
        cv2.putText(frame, (spot_pos[0]+5, spot_pos[1]+height-5), cv2.FONT_HERSHEY_PLAIN, 2, (255,255,255),2)
    for car in cars:
        x1, y1, x2, y2 = car['bbox']
        cv2.rectangle(frame, (x1, y1), (x2, y2), (255,255,255), 2)
        cv2.putText(frame, f'xe', (x1,y1-10), cv2.FONT_HERSHEY_PLAIN, 2, (255,255,255),2)

    return frame


def hightlight_nearest_spot(frame, nearest_spot):
    if nearest_spot:
        spot_pos, distance = nearest_spot[0]
        cv2.rectangle(frame,spot_pos, (spot_pos[0] + width, spot_pos[1]), (255,255,255), 2)
        cv2.putText(frame, "GOI Y",
                    (spot_pos[0] + width // 2 - 20, spot_pos[1] + height // 2),
                    cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 255, 255), 2)

    return frame


def analyze_parking_lot(frame):
    """PhÃ¢n tÃ­ch toÃ n bá»™ bÃ£i Ä‘á»— xe - hÃ m chÃ­nh"""
    global VT, VT_history

    # PhÃ¡t hiá»‡n xe
    cars = phatHienXe(frame)

    empty_spots = []
    occupied_spots = []

    # Kiá»ƒm tra tá»«ng chá»— Ä‘á»—
    for i, spot_pos in enumerate(VT):
        is_occupied, confidence = kiemTraChoCoBiChiem(spot_pos,cars)
        final_occupied = update_spot_history(i, is_occupied)

        if final_occupied:
            occupied_spots.append(spot_pos)
        else:
            empty_spots.append(spot_pos)

    return cars, empty_spots, occupied_spots


def process_frame(frame):
    """Xá»­ lÃ½ má»™t frame vÃ  tráº£ vá» káº¿t quáº£"""
    # PhÃ¢n tÃ­ch bÃ£i Ä‘á»— xe
    cars, empty_spots, occupied_spots = analyze_parking_lot(frame)

    # TÃ¬m chá»— trá»‘ng gáº§n nháº¥t
    nearest_spots = timChodau(empty_spots)

    # Váº½ káº¿t quáº£ lÃªn frame
    result_frame = frame.copy()
    result_frame = draw_packing_spot(result_frame, empty_spots, occupied_spots, cars)

    if nearest_spots:
        result_frame = hightlight_nearest_spot(result_frame, nearest_spots)

    result_frame = draw_packing_infor(result_frame, empty_spots, occupied_spots, len(cars),
                                     nearest_spots[0] if nearest_spots else None)

    return result_frame, len(cars), len(empty_spots), len(occupied_spots)


def run_parking_system():
    """HÃ m chÃ­nh cháº¡y há»‡ thá»‘ng"""
    # Khá»Ÿi táº¡o há»‡ thá»‘ng
    if not khoiTao():
        print("âŒ Khá»Ÿi táº¡o há»‡ thá»‘ng tháº¥t báº¡i")
        return

    # Kiá»ƒm tra tÃ­nh há»£p lá»‡ cá»§a vá»‹ trÃ­ Ä‘á»— xe
    if not kiemTraVT():
        print("âŒ Vá»‹ trÃ­ Ä‘á»— xe khÃ´ng há»£p lá»‡")
        return

    # Má»Ÿ video
    cap = cv2.VideoCapture(videoPath)
    if not cap.isOpened():
        print(f"âŒ KhÃ´ng thá»ƒ má»Ÿ video: {videoPath}")
        return

    print("\nğŸ® Äiá»u khiá»ƒn:")
    print("  - Nháº¥n 'q' Ä‘á»ƒ thoÃ¡t")
    print("  - Nháº¥n 'p' Ä‘á»ƒ táº¡m dá»«ng")
    print("  - Nháº¥n 'i' Ä‘á»ƒ xem thÃ´ng tin file")

    fps_counter = 0
    start_time = time.time()
    paused = False

    while True:
        if not paused:
            ret, frame = cap.read()
            if not ret:
                print("âœ… ÄÃ£ xá»­ lÃ½ háº¿t video")
                break

            # Xá»­ lÃ½ frame
            processed_frame, vehicle_count, empty_count, occupied_count = process_frame(frame)

            # Hiá»ƒn thá»‹ FPS
            fps_counter += 1
            if time.time() - start_time >= 1.0:
                fps = fps_counter / (time.time() - start_time)
                cv2.putText(processed_frame, f"FPS: {fps:.1f}",
                            (10, processed_frame.shape[0] - 10),
                            cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 255, 255), 2)
                fps_counter = 0
                start_time = time.time()

            cv2.imshow('ğŸš— He thong quan ly bai do xe', processed_frame)

        # Xá»­ lÃ½ phÃ­m
        key = cv2.waitKey(1 if not paused else 0) & 0xFF
        if key == ord('q'):
            break
        elif key == ord('p'):
            paused = not paused
            print("â¸ï¸ Táº¡m dá»«ng" if paused else "â–¶ï¸ Tiáº¿p tá»¥c")
        elif key == ord('i'):
            print(f"\nğŸ“ ThÃ´ng tin file Ä‘ang sá»­ dá»¥ng:")
            print(f"   ÄÆ°á»ng dáº«n: {viTri}")
            print(f"   Sá»‘ chá»— Ä‘á»—: {len(VT)}")
            print(f"   Tá»“n táº¡i: {os.path.exists(videoPath)}")

    cap.release()
    cv2.destroyAllWindows()
    print("âœ… ÄÃ£ thoÃ¡t há»‡ thá»‘ng")