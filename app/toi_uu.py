import cv2
import numpy as np
from ultralytics import YOLO
from collections import deque
import time

# =============================
# üéØ C·∫§U H√åNH
# =============================
VIDEO_PATH = 'E:\\WORKSPACE\\packing-plot\\carPark.mp4'
MODEL_PATH = 'E:\\WORKSPACE\\packing-plot\\models\\yolo11_finetnune2class.pt'

# Class IDs
EMPTY_SPOT_CLASS = 0  # "empty_spot"
OCCUPIED_SPOT_CLASS = 1  # "occupied_spot"

CONFIDENCE = 0.6
IOU_THRESHOLD = 0.5

# Bi·∫øn to√†n c·ª•c
model = None
spot_history = {}


def initialize_system():
    """Kh·ªüi t·∫°o h·ªá th·ªëng"""
    global model
    try:
        model = YOLO(MODEL_PATH)
        print("‚úÖ ƒê√£ t·∫£i model YOLO")
        return True
    except Exception as e:
        print(f"‚ùå L·ªói t·∫£i model: {e}")
        return False


def detect_spots_yolo(frame):
    """YOLO detect ch·ªó ƒë·ªó v√† tr·∫°ng th√°i"""
    results = model(frame, conf=CONFIDENCE, iou=IOU_THRESHOLD, verbose=False)

    yolo_empty = []
    yolo_occupied = []
    all_yolo_spots = []

    for result in results:
        for box in result.boxes:
            x1, y1, x2, y2 = map(int, box.xyxy[0])
            conf = box.conf[0].item()
            class_id = int(box.cls[0])

            spot_info = {
                'bbox': (x1, y1, x2, y2),
                'class_id': class_id,
                'confidence': conf,
                'center': ((x1 + x2) // 2, (y1 + y2) // 2),
                'area': (x2 - x1) * (y2 - y1),
                'method': 'yolo'
            }

            all_yolo_spots.append(spot_info)

            if class_id == EMPTY_SPOT_CLASS:
                yolo_empty.append(spot_info)
            elif class_id == OCCUPIED_SPOT_CLASS:
                yolo_occupied.append(spot_info)

    return yolo_empty, yolo_occupied, all_yolo_spots


def get_spot_color(class_id):
    """üéØ Ch·ªâ tr·∫£ v·ªÅ m√†u s·∫Øc - KH√îNG TEXT"""
    if class_id == EMPTY_SPOT_CLASS:
        return (0, 255, 0)  # üü¢ XANH - Tr·ªëng
    elif class_id == OCCUPIED_SPOT_CLASS:
        return (0, 0, 255)  # üî¥ ƒê·ªé - C√≥ xe
    else:
        return (255, 255, 0)  # üü° V√ÄNG - Kh√¥ng r√µ


def draw_simple_results(frame, yolo_spots, merged_empty, merged_occupied):
    """V·∫Ω k·∫øt qu·∫£ ƒë∆°n gi·∫£n - CH·ªà M√ÄU S·∫ÆC"""

    # üéØ V·∫º K·∫æT QU·∫¢ MERGED (ch√≠nh th·ª©c)
    for spot in merged_empty + merged_occupied:
        x1, y1, x2, y2 = spot['bbox']

        # üéØ L·∫•y m√†u d·ª±a tr√™n class_id
        if 'class_id' in spot:
            color = get_spot_color(spot['class_id'])
        else:
            # M·∫∑c ƒë·ªãnh d·ª±a tr√™n danh s√°ch
            color = (0, 255, 0) if spot in merged_empty else (0, 0, 255)

        # V·∫Ω box v·ªõi m√†u s·∫Øc
        cv2.rectangle(frame, (x1, y1), (x2, y2), color, 3)

        # üéØ V·∫º S·ªê TH·ª® T·ª∞ (t√πy ch·ªçn)
        spot_id = f"{x1 // 20}_{y1 // 20}"
        cv2.putText(frame, "#", (x1 + 5, y1 + 15),
                    cv2.FONT_HERSHEY_SIMPLEX, 0.4, (255, 255, 255), 1)

    # üéØ TH·ªêNG K√ä ƒê∆†N GI·∫¢N
    total_empty = len(merged_empty)
    total_occupied = len(merged_occupied)
    total_spots = total_empty + total_occupied

    # Background cho th·ªëng k√™
    cv2.rectangle(frame, (5, 5), (300, 90), (0, 0, 0), -1)

    cv2.putText(frame, f"TONG CHO: {total_spots}",
                (10, 25), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 255, 255), 2)

    # üü¢ Tr·ªëng - m√†u xanh
    cv2.putText(frame, f"TRONG: {total_empty}",
                (10, 50), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 255, 0), 2)

    # üî¥ C√≥ xe - m√†u ƒë·ªè
    cv2.putText(frame, f"CO XE: {total_occupied}",
                (10, 75), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 0, 255), 2)

    return frame


def detect_spots_opencv(frame):
    """OpenCV detect ch·ªó ƒë·ªó t·ª± ƒë·ªông"""
    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)
    blurred = cv2.GaussianBlur(gray, (5, 5), 0)
    edges = cv2.Canny(blurred, 50, 150)

    contours, _ = cv2.findContours(edges, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)

    opencv_spots = []

    for contour in contours:
        area = cv2.contourArea(contour)
        if 800 < area < 15000:
            x, y, w, h = cv2.boundingRect(contour)
            aspect_ratio = w / h if h > 0 else 0

            if 1.2 < aspect_ratio < 5.0:
                opencv_spots.append({
                    'bbox': (x, y, x + w, y + h),
                    'area': area,
                    'aspect_ratio': aspect_ratio,
                    'center': (x + w // 2, y + h // 2),
                    'method': 'opencv'
                })

    return opencv_spots, edges


def analyze_spot_status_opencv(frame, spots):
    """Ph√¢n t√≠ch tr·∫°ng th√°i ch·ªó ƒë·ªó b·∫±ng OpenCV"""
    empty_spots = []
    occupied_spots = []

    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)

    for spot in spots:
        x1, y1, x2, y2 = spot['bbox']
        roi = gray[y1:y2, x1:x2]

        if roi.size == 0:
            continue

        laplacian_var = cv2.Laplacian(roi, cv2.CV_64F).var()
        occupancy_score = min(laplacian_var / 500, 1.0)

        if occupancy_score > 0.3:
            spot['class_id'] = OCCUPIED_SPOT_CLASS
            occupied_spots.append(spot)
        else:
            spot['class_id'] = EMPTY_SPOT_CLASS
            empty_spots.append(spot)

    return empty_spots, occupied_spots


def merge_detections(yolo_empty, yolo_occupied, opencv_empty, opencv_occupied):
    """K·∫øt h·ª£p k·∫øt qu·∫£ t·ª´ YOLO v√† OpenCV"""

    def get_spot_id(spot):
        x1, y1, x2, y2 = spot['bbox']
        return f"{x1 // 15}_{y1 // 15}"

    merged_empty = []
    merged_occupied = []
    processed_spots = {}

    # ∆Øu ti√™n YOLO DETECTION
    for spot in yolo_empty + yolo_occupied:
        spot_id = get_spot_id(spot)
        if spot_id not in processed_spots:
            processed_spots[spot_id] = True
            if spot['class_id'] == EMPTY_SPOT_CLASS:
                merged_empty.append(spot)
            else:
                merged_occupied.append(spot)

    # B·ªï sung OPENCV
    for spot in opencv_empty + opencv_occupied:
        spot_id = get_spot_id(spot)
        if spot_id not in processed_spots:
            processed_spots[spot_id] = True
            if 'class_id' in spot and spot['class_id'] == EMPTY_SPOT_CLASS:
                merged_empty.append(spot)
            elif 'class_id' in spot and spot['class_id'] == OCCUPIED_SPOT_CLASS:
                merged_occupied.append(spot)
            else:
                if spot in opencv_empty:
                    spot['class_id'] = EMPTY_SPOT_CLASS
                    merged_empty.append(spot)
                else:
                    spot['class_id'] = OCCUPIED_SPOT_CLASS
                    merged_occupied.append(spot)

    return merged_empty, merged_occupied


def main_simple():
    """H·ªá th·ªëng ƒë∆°n gi·∫£n - CH·ªà M√ÄU S·∫ÆC"""
    if not initialize_system():
        return

    cap = cv2.VideoCapture(VIDEO_PATH)

    print("üöÄ H·ªÜ TH·ªêNG ƒê∆†N GI·∫¢N")
    print("üé® Tr·ªëng: üü¢ XANH | C√≥ xe: üî¥ ƒê·ªé")
    print("üìä Ch·ªâ hi·ªÉn th·ªã th·ªëng k√™, kh√¥ng text tr√™n box")

    fps_counter = 0
    start_time = time.time()

    while True:
        ret, frame = cap.read()
        if not ret:
            break

        fps_counter += 1

        # YOLO DETECTION
        yolo_empty, yolo_occupied, all_yolo_spots = detect_spots_yolo(frame)

        # OPENCV DETECTION
        opencv_spots, edges_frame = detect_spots_opencv(frame)
        opencv_empty, opencv_occupied = analyze_spot_status_opencv(frame, opencv_spots)

        # MERGE RESULTS
        merged_empty, merged_occupied = merge_detections(
            yolo_empty, yolo_occupied, opencv_empty, opencv_occupied
        )

        # üéØ V·∫º K·∫æT QU·∫¢ ƒê∆†N GI·∫¢N
        result_frame = draw_simple_results(frame, all_yolo_spots, merged_empty, merged_occupied)

        # FPS
        if time.time() - start_time >= 1.0:
            fps = fps_counter / (time.time() - start_time)
            cv2.putText(result_frame, f"FPS: {fps:.1f}",
                        (10, result_frame.shape[0] - 10),
                        cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 1)
            fps_counter = 0
            start_time = time.time()

        cv2.imshow('üöó Simple Parking System', result_frame)

        if cv2.waitKey(1) & 0xFF == ord('q'):
            break

    cap.release()
    cv2.destroyAllWindows()


if __name__ == "__main__":
    main_simple()